{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Data Analysis with Python\n",
    "\n",
    "\n",
    "## What is Pandas?\n",
    "\n",
    "Pandas is a high-performance data analysis tools.\n",
    "\n",
    "Use it to:\n",
    "\n",
    "1. Load data (various format supported)\n",
    "2. Prepare data (clean data, merge data, select subset of data)\n",
    "3. Analyse data (plot, print, compute indicators such as max, min, mean)\n",
    "4. Output data (into various formats)\n",
    "\n",
    "## Installation\n",
    "\n",
    "* If you have Anaconda: Already installed\n",
    "* If you have Miniconda: \n",
    "   ```bash\n",
    "   conda install pandas\n",
    "   ```\n",
    "* If you have your another Python distribution: \n",
    "   ```\n",
    "   pip install pandas --user\n",
    "   ```\n",
    "\n",
    "## More information\n",
    "\n",
    "* Pandas cookbook: http://pandas.pydata.org/pandas-docs/stable/cookbook.html\n",
    "* Official Pandas documentation: http://pandas.pydata.org/pandas-docs/stable/tutorials.html \n",
    "* Wes MecKinney, Python for Data Analysis \n",
    "![Python for Data Analysis](images/python_for_data_analysis.gif \"Python for Data Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf1409/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2881: FutureWarning: \n",
      "mpl_style had been deprecated and will be removed in a future version.\n",
      "Use `matplotlib.pyplot.style.use` instead.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd   # pd is now an alias for pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make the graphs a bit prettier\n",
    "pd.set_option('display.mpl_style', 'default') \n",
    "plt.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting data sources\n",
    "\n",
    "### Statistisk sentralbyr√•\n",
    "https://www.ssb.no\n",
    "\n",
    "### Finn API \n",
    "https://www.finn.no/api\n",
    "\n",
    "### Ruter API \n",
    "https://ruter.no/labs/\n",
    "\n",
    "### YR data\n",
    "http://om.yr.no/verdata/free-weather-data/\n",
    "\n",
    "### Oslo Bysykkel API\n",
    "https://developer.oslobysykkel.no/data\n",
    "\n",
    "### Financial and economic data\n",
    "https://www.quandl.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Oslo Bysykkel data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit https://developer.oslobysykkel.no/data and download the trip data of each month in CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in data\n",
    "\n",
    "Pandas offers many drivers to load data in different formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: A numpy array can be loaded into Pandas with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.186406</td>\n",
       "      <td>1.280073</td>\n",
       "      <td>0.428085</td>\n",
       "      <td>-0.756351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.154418</td>\n",
       "      <td>0.570225</td>\n",
       "      <td>0.256553</td>\n",
       "      <td>1.152159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.163652</td>\n",
       "      <td>0.491326</td>\n",
       "      <td>-0.363586</td>\n",
       "      <td>0.553840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.095924</td>\n",
       "      <td>-1.472496</td>\n",
       "      <td>-0.547212</td>\n",
       "      <td>1.263573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.983460</td>\n",
       "      <td>0.865649</td>\n",
       "      <td>-0.082865</td>\n",
       "      <td>0.876780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.017322</td>\n",
       "      <td>-1.078749</td>\n",
       "      <td>-0.324283</td>\n",
       "      <td>-0.892761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.567959</td>\n",
       "      <td>-0.310224</td>\n",
       "      <td>-0.423149</td>\n",
       "      <td>1.420498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.835418</td>\n",
       "      <td>-0.462227</td>\n",
       "      <td>0.327926</td>\n",
       "      <td>-0.957586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0 -0.186406  1.280073  0.428085 -0.756351\n",
       "1 -1.154418  0.570225  0.256553  1.152159\n",
       "2 -1.163652  0.491326 -0.363586  0.553840\n",
       "3  1.095924 -1.472496 -0.547212  1.263573\n",
       "4  1.983460  0.865649 -0.082865  0.876780\n",
       "5  1.017322 -1.078749 -0.324283 -0.892761\n",
       "6  0.567959 -0.310224 -0.423149  1.420498\n",
       "7 -0.835418 -0.462227  0.327926 -0.957586"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.random.randn(8, 4)\n",
    "pd.DataFrame(array, columns=[\"A\", \"B\", \"C\", \"D\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the Oslo Byskkel data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downloaded the bysykkel data [from here](https://developer.oslobysykkel.no/data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 sf1409 sf1409 14M nov.  22 20:17 data/bysykkel/trips-2016.10.1-2016.10.31.csv\r\n",
      "-rw-rw-r-- 1 sf1409 sf1409 21M nov.  22 20:17 data/bysykkel/trips-2016.8.1-2016.8.31.csv\r\n",
      "-rw-rw-r-- 1 sf1409 sf1409 22M nov.  22 20:17 data/bysykkel/trips-2016.9.1-2016.9.30.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -hl data/bysykkel/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the bash command `head` to inspect the first lines of one of the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start station,Start time,End station,End time\r\n",
      "283,2016-10-01 06:00:08 +0200,238,2016-10-01 06:09:47 +0200\r\n",
      "169,2016-10-01 06:00:41 +0200,175,2016-10-01 06:11:07 +0200\r\n",
      "211,2016-10-01 06:01:02 +0200,162,2016-10-01 06:15:52 +0200\r\n",
      "200,2016-10-01 06:01:20 +0200,163,2016-10-01 06:15:04 +0200\r\n",
      "157,2016-10-01 06:02:16 +0200,163,2016-10-01 06:04:29 +0200\r\n",
      "177,2016-10-01 06:04:22 +0200,179,2016-10-01 06:24:40 +0200\r\n",
      "257,2016-10-01 06:04:39 +0200,199,2016-10-01 06:16:09 +0200\r\n",
      "191,2016-10-01 06:05:54 +0200,191,2016-10-01 06:06:21 +0200\r\n",
      "191,2016-10-01 06:06:01 +0200,167,2016-10-01 06:15:40 +0200\r\n"
     ]
    }
   ],
   "source": [
    "!head data/bysykkel/trips-2016.10.1-2016.10.31.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we are dealing with a comma seperated file with four columns and a header line. \n",
    "Loading this data into Pandas is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_stats = pd.read_csv('data/bysykkel/trips-2016.10.1-2016.10.31.csv', sep=',')\n",
    "type(bike_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start station</th>\n",
       "      <th>Start time</th>\n",
       "      <th>End station</th>\n",
       "      <th>End time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>2016-10-01 06:00:08 +0200</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2016-10-01 06:09:47 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169</td>\n",
       "      <td>2016-10-01 06:00:41 +0200</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2016-10-01 06:11:07 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211</td>\n",
       "      <td>2016-10-01 06:01:02 +0200</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2016-10-01 06:15:52 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>2016-10-01 06:01:20 +0200</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2016-10-01 06:15:04 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>2016-10-01 06:02:16 +0200</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2016-10-01 06:04:29 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>177</td>\n",
       "      <td>2016-10-01 06:04:22 +0200</td>\n",
       "      <td>179.0</td>\n",
       "      <td>2016-10-01 06:24:40 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>257</td>\n",
       "      <td>2016-10-01 06:04:39 +0200</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2016-10-01 06:16:09 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>191</td>\n",
       "      <td>2016-10-01 06:05:54 +0200</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2016-10-01 06:06:21 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>191</td>\n",
       "      <td>2016-10-01 06:06:01 +0200</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2016-10-01 06:15:40 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>181</td>\n",
       "      <td>2016-10-01 06:06:13 +0200</td>\n",
       "      <td>251.0</td>\n",
       "      <td>2016-10-01 06:18:34 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>210</td>\n",
       "      <td>2016-10-01 06:06:16 +0200</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2016-10-01 06:11:34 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>191</td>\n",
       "      <td>2016-10-01 06:06:36 +0200</td>\n",
       "      <td>222.0</td>\n",
       "      <td>2016-10-01 06:09:59 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>228</td>\n",
       "      <td>2016-10-01 06:08:01 +0200</td>\n",
       "      <td>247.0</td>\n",
       "      <td>2016-10-01 06:15:01 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>175</td>\n",
       "      <td>2016-10-01 06:08:22 +0200</td>\n",
       "      <td>222.0</td>\n",
       "      <td>2016-10-01 06:14:44 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>219</td>\n",
       "      <td>2016-10-01 06:11:44 +0200</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2016-10-01 06:18:42 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>211</td>\n",
       "      <td>2016-10-01 06:12:00 +0200</td>\n",
       "      <td>235.0</td>\n",
       "      <td>2016-10-01 06:18:41 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>219</td>\n",
       "      <td>2016-10-01 06:13:26 +0200</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2016-10-01 06:24:42 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>198</td>\n",
       "      <td>2016-10-01 06:15:22 +0200</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2016-10-01 06:25:26 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>242</td>\n",
       "      <td>2016-10-01 06:15:34 +0200</td>\n",
       "      <td>211.0</td>\n",
       "      <td>2016-10-01 06:25:34 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>233</td>\n",
       "      <td>2016-10-01 06:17:36 +0200</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2016-10-01 06:31:11 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>228</td>\n",
       "      <td>2016-10-01 06:18:04 +0200</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2016-10-01 06:27:16 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>240</td>\n",
       "      <td>2016-10-01 06:18:43 +0200</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2016-10-01 06:22:47 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>235</td>\n",
       "      <td>2016-10-01 06:21:49 +0200</td>\n",
       "      <td>211.0</td>\n",
       "      <td>2016-10-01 06:27:46 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>201</td>\n",
       "      <td>2016-10-01 06:22:04 +0200</td>\n",
       "      <td>281.0</td>\n",
       "      <td>2016-10-01 06:25:49 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>272</td>\n",
       "      <td>2016-10-01 06:22:17 +0200</td>\n",
       "      <td>251.0</td>\n",
       "      <td>2016-10-01 06:34:22 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>222</td>\n",
       "      <td>2016-10-01 06:24:50 +0200</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2016-10-01 06:30:39 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>208</td>\n",
       "      <td>2016-10-01 06:26:13 +0200</td>\n",
       "      <td>253.0</td>\n",
       "      <td>2016-10-01 06:33:20 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>183</td>\n",
       "      <td>2016-10-01 06:26:55 +0200</td>\n",
       "      <td>248.0</td>\n",
       "      <td>2016-10-01 06:34:09 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>298</td>\n",
       "      <td>2016-10-01 06:27:06 +0200</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2016-10-01 06:38:20 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>242</td>\n",
       "      <td>2016-10-01 06:29:20 +0200</td>\n",
       "      <td>301.0</td>\n",
       "      <td>2016-10-01 06:38:25 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242728</th>\n",
       "      <td>190</td>\n",
       "      <td>2016-10-31 23:33:37 +0100</td>\n",
       "      <td>272.0</td>\n",
       "      <td>2016-10-31 23:40:34 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242729</th>\n",
       "      <td>228</td>\n",
       "      <td>2016-10-31 23:33:55 +0100</td>\n",
       "      <td>233.0</td>\n",
       "      <td>2016-10-31 23:36:50 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242730</th>\n",
       "      <td>226</td>\n",
       "      <td>2016-10-31 23:34:59 +0100</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2016-10-31 23:37:07 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242731</th>\n",
       "      <td>186</td>\n",
       "      <td>2016-10-31 23:35:02 +0100</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2016-10-31 23:44:13 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242732</th>\n",
       "      <td>248</td>\n",
       "      <td>2016-10-31 23:35:06 +0100</td>\n",
       "      <td>233.0</td>\n",
       "      <td>2016-10-31 23:53:57 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242733</th>\n",
       "      <td>194</td>\n",
       "      <td>2016-10-31 23:35:52 +0100</td>\n",
       "      <td>229.0</td>\n",
       "      <td>2016-10-31 23:46:51 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242734</th>\n",
       "      <td>298</td>\n",
       "      <td>2016-10-31 23:36:31 +0100</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2016-10-31 23:41:20 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242735</th>\n",
       "      <td>294</td>\n",
       "      <td>2016-10-31 23:36:41 +0100</td>\n",
       "      <td>204.0</td>\n",
       "      <td>2016-10-31 23:40:40 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242736</th>\n",
       "      <td>210</td>\n",
       "      <td>2016-10-31 23:36:58 +0100</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2016-10-31 23:46:21 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242737</th>\n",
       "      <td>218</td>\n",
       "      <td>2016-10-31 23:37:09 +0100</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2016-10-31 23:47:50 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242738</th>\n",
       "      <td>164</td>\n",
       "      <td>2016-10-31 23:38:49 +0100</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2016-10-31 23:47:52 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242739</th>\n",
       "      <td>182</td>\n",
       "      <td>2016-10-31 23:39:52 +0100</td>\n",
       "      <td>189.0</td>\n",
       "      <td>2016-10-31 23:48:26 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242740</th>\n",
       "      <td>298</td>\n",
       "      <td>2016-10-31 23:40:53 +0100</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2016-10-31 23:45:35 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242741</th>\n",
       "      <td>228</td>\n",
       "      <td>2016-10-31 23:41:10 +0100</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2016-10-31 23:46:38 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242742</th>\n",
       "      <td>181</td>\n",
       "      <td>2016-10-31 23:45:44 +0100</td>\n",
       "      <td>292.0</td>\n",
       "      <td>2016-10-31 23:53:31 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242743</th>\n",
       "      <td>260</td>\n",
       "      <td>2016-10-31 23:45:59 +0100</td>\n",
       "      <td>294.0</td>\n",
       "      <td>2016-11-01 00:04:43 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242744</th>\n",
       "      <td>189</td>\n",
       "      <td>2016-10-31 23:46:57 +0100</td>\n",
       "      <td>275.0</td>\n",
       "      <td>2016-11-01 01:45:11 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242745</th>\n",
       "      <td>226</td>\n",
       "      <td>2016-10-31 23:47:20 +0100</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2016-11-01 00:02:10 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242746</th>\n",
       "      <td>200</td>\n",
       "      <td>2016-10-31 23:48:23 +0100</td>\n",
       "      <td>222.0</td>\n",
       "      <td>2016-11-01 00:00:46 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242747</th>\n",
       "      <td>287</td>\n",
       "      <td>2016-10-31 23:49:13 +0100</td>\n",
       "      <td>204.0</td>\n",
       "      <td>2016-10-31 23:55:26 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242748</th>\n",
       "      <td>301</td>\n",
       "      <td>2016-10-31 23:49:51 +0100</td>\n",
       "      <td>275.0</td>\n",
       "      <td>2016-10-31 23:54:29 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242749</th>\n",
       "      <td>185</td>\n",
       "      <td>2016-10-31 23:50:10 +0100</td>\n",
       "      <td>228.0</td>\n",
       "      <td>2016-11-01 00:05:47 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242750</th>\n",
       "      <td>226</td>\n",
       "      <td>2016-10-31 23:50:29 +0100</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2016-10-31 23:55:14 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242751</th>\n",
       "      <td>233</td>\n",
       "      <td>2016-10-31 23:52:09 +0100</td>\n",
       "      <td>233.0</td>\n",
       "      <td>2016-11-01 00:07:33 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242752</th>\n",
       "      <td>211</td>\n",
       "      <td>2016-10-31 23:52:24 +0100</td>\n",
       "      <td>281.0</td>\n",
       "      <td>2016-11-01 01:17:32 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242753</th>\n",
       "      <td>284</td>\n",
       "      <td>2016-10-31 23:53:30 +0100</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2016-11-01 00:04:13 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242754</th>\n",
       "      <td>218</td>\n",
       "      <td>2016-10-31 23:53:48 +0100</td>\n",
       "      <td>292.0</td>\n",
       "      <td>2016-11-01 00:09:17 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242755</th>\n",
       "      <td>204</td>\n",
       "      <td>2016-10-31 23:54:28 +0100</td>\n",
       "      <td>277.0</td>\n",
       "      <td>2016-11-01 00:01:59 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242756</th>\n",
       "      <td>204</td>\n",
       "      <td>2016-10-31 23:56:57 +0100</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2016-11-01 00:02:16 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242757</th>\n",
       "      <td>268</td>\n",
       "      <td>2016-10-31 23:59:10 +0100</td>\n",
       "      <td>299.0</td>\n",
       "      <td>2016-11-01 00:04:55 +0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242758 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Start station                 Start time  End station  \\\n",
       "0                 283  2016-10-01 06:00:08 +0200        238.0   \n",
       "1                 169  2016-10-01 06:00:41 +0200        175.0   \n",
       "2                 211  2016-10-01 06:01:02 +0200        162.0   \n",
       "3                 200  2016-10-01 06:01:20 +0200        163.0   \n",
       "4                 157  2016-10-01 06:02:16 +0200        163.0   \n",
       "5                 177  2016-10-01 06:04:22 +0200        179.0   \n",
       "6                 257  2016-10-01 06:04:39 +0200        199.0   \n",
       "7                 191  2016-10-01 06:05:54 +0200        191.0   \n",
       "8                 191  2016-10-01 06:06:01 +0200        167.0   \n",
       "9                 181  2016-10-01 06:06:13 +0200        251.0   \n",
       "10                210  2016-10-01 06:06:16 +0200        163.0   \n",
       "11                191  2016-10-01 06:06:36 +0200        222.0   \n",
       "12                228  2016-10-01 06:08:01 +0200        247.0   \n",
       "13                175  2016-10-01 06:08:22 +0200        222.0   \n",
       "14                219  2016-10-01 06:11:44 +0200        192.0   \n",
       "15                211  2016-10-01 06:12:00 +0200        235.0   \n",
       "16                219  2016-10-01 06:13:26 +0200        192.0   \n",
       "17                198  2016-10-01 06:15:22 +0200        201.0   \n",
       "18                242  2016-10-01 06:15:34 +0200        211.0   \n",
       "19                233  2016-10-01 06:17:36 +0200        200.0   \n",
       "20                228  2016-10-01 06:18:04 +0200        181.0   \n",
       "21                240  2016-10-01 06:18:43 +0200        252.0   \n",
       "22                235  2016-10-01 06:21:49 +0200        211.0   \n",
       "23                201  2016-10-01 06:22:04 +0200        281.0   \n",
       "24                272  2016-10-01 06:22:17 +0200        251.0   \n",
       "25                222  2016-10-01 06:24:50 +0200        192.0   \n",
       "26                208  2016-10-01 06:26:13 +0200        253.0   \n",
       "27                183  2016-10-01 06:26:55 +0200        248.0   \n",
       "28                298  2016-10-01 06:27:06 +0200        196.0   \n",
       "29                242  2016-10-01 06:29:20 +0200        301.0   \n",
       "...               ...                        ...          ...   \n",
       "242728            190  2016-10-31 23:33:37 +0100        272.0   \n",
       "242729            228  2016-10-31 23:33:55 +0100        233.0   \n",
       "242730            226  2016-10-31 23:34:59 +0100        164.0   \n",
       "242731            186  2016-10-31 23:35:02 +0100        164.0   \n",
       "242732            248  2016-10-31 23:35:06 +0100        233.0   \n",
       "242733            194  2016-10-31 23:35:52 +0100        229.0   \n",
       "242734            298  2016-10-31 23:36:31 +0100        218.0   \n",
       "242735            294  2016-10-31 23:36:41 +0100        204.0   \n",
       "242736            210  2016-10-31 23:36:58 +0100        190.0   \n",
       "242737            218  2016-10-31 23:37:09 +0100        164.0   \n",
       "242738            164  2016-10-31 23:38:49 +0100        161.0   \n",
       "242739            182  2016-10-31 23:39:52 +0100        189.0   \n",
       "242740            298  2016-10-31 23:40:53 +0100        264.0   \n",
       "242741            228  2016-10-31 23:41:10 +0100        238.0   \n",
       "242742            181  2016-10-31 23:45:44 +0100        292.0   \n",
       "242743            260  2016-10-31 23:45:59 +0100        294.0   \n",
       "242744            189  2016-10-31 23:46:57 +0100        275.0   \n",
       "242745            226  2016-10-31 23:47:20 +0100        175.0   \n",
       "242746            200  2016-10-31 23:48:23 +0100        222.0   \n",
       "242747            287  2016-10-31 23:49:13 +0100        204.0   \n",
       "242748            301  2016-10-31 23:49:51 +0100        275.0   \n",
       "242749            185  2016-10-31 23:50:10 +0100        228.0   \n",
       "242750            226  2016-10-31 23:50:29 +0100        210.0   \n",
       "242751            233  2016-10-31 23:52:09 +0100        233.0   \n",
       "242752            211  2016-10-31 23:52:24 +0100        281.0   \n",
       "242753            284  2016-10-31 23:53:30 +0100        164.0   \n",
       "242754            218  2016-10-31 23:53:48 +0100        292.0   \n",
       "242755            204  2016-10-31 23:54:28 +0100        277.0   \n",
       "242756            204  2016-10-31 23:56:57 +0100        201.0   \n",
       "242757            268  2016-10-31 23:59:10 +0100        299.0   \n",
       "\n",
       "                         End time  \n",
       "0       2016-10-01 06:09:47 +0200  \n",
       "1       2016-10-01 06:11:07 +0200  \n",
       "2       2016-10-01 06:15:52 +0200  \n",
       "3       2016-10-01 06:15:04 +0200  \n",
       "4       2016-10-01 06:04:29 +0200  \n",
       "5       2016-10-01 06:24:40 +0200  \n",
       "6       2016-10-01 06:16:09 +0200  \n",
       "7       2016-10-01 06:06:21 +0200  \n",
       "8       2016-10-01 06:15:40 +0200  \n",
       "9       2016-10-01 06:18:34 +0200  \n",
       "10      2016-10-01 06:11:34 +0200  \n",
       "11      2016-10-01 06:09:59 +0200  \n",
       "12      2016-10-01 06:15:01 +0200  \n",
       "13      2016-10-01 06:14:44 +0200  \n",
       "14      2016-10-01 06:18:42 +0200  \n",
       "15      2016-10-01 06:18:41 +0200  \n",
       "16      2016-10-01 06:24:42 +0200  \n",
       "17      2016-10-01 06:25:26 +0200  \n",
       "18      2016-10-01 06:25:34 +0200  \n",
       "19      2016-10-01 06:31:11 +0200  \n",
       "20      2016-10-01 06:27:16 +0200  \n",
       "21      2016-10-01 06:22:47 +0200  \n",
       "22      2016-10-01 06:27:46 +0200  \n",
       "23      2016-10-01 06:25:49 +0200  \n",
       "24      2016-10-01 06:34:22 +0200  \n",
       "25      2016-10-01 06:30:39 +0200  \n",
       "26      2016-10-01 06:33:20 +0200  \n",
       "27      2016-10-01 06:34:09 +0200  \n",
       "28      2016-10-01 06:38:20 +0200  \n",
       "29      2016-10-01 06:38:25 +0200  \n",
       "...                           ...  \n",
       "242728  2016-10-31 23:40:34 +0100  \n",
       "242729  2016-10-31 23:36:50 +0100  \n",
       "242730  2016-10-31 23:37:07 +0100  \n",
       "242731  2016-10-31 23:44:13 +0100  \n",
       "242732  2016-10-31 23:53:57 +0100  \n",
       "242733  2016-10-31 23:46:51 +0100  \n",
       "242734  2016-10-31 23:41:20 +0100  \n",
       "242735  2016-10-31 23:40:40 +0100  \n",
       "242736  2016-10-31 23:46:21 +0100  \n",
       "242737  2016-10-31 23:47:50 +0100  \n",
       "242738  2016-10-31 23:47:52 +0100  \n",
       "242739  2016-10-31 23:48:26 +0100  \n",
       "242740  2016-10-31 23:45:35 +0100  \n",
       "242741  2016-10-31 23:46:38 +0100  \n",
       "242742  2016-10-31 23:53:31 +0100  \n",
       "242743  2016-11-01 00:04:43 +0100  \n",
       "242744  2016-11-01 01:45:11 +0100  \n",
       "242745  2016-11-01 00:02:10 +0100  \n",
       "242746  2016-11-01 00:00:46 +0100  \n",
       "242747  2016-10-31 23:55:26 +0100  \n",
       "242748  2016-10-31 23:54:29 +0100  \n",
       "242749  2016-11-01 00:05:47 +0100  \n",
       "242750  2016-10-31 23:55:14 +0100  \n",
       "242751  2016-11-01 00:07:33 +0100  \n",
       "242752  2016-11-01 01:17:32 +0100  \n",
       "242753  2016-11-01 00:04:13 +0100  \n",
       "242754  2016-11-01 00:09:17 +0100  \n",
       "242755  2016-11-01 00:01:59 +0100  \n",
       "242756  2016-11-01 00:02:16 +0100  \n",
       "242757  2016-11-01 00:04:55 +0100  \n",
       "\n",
       "[242758 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Pandas automatically used the first line as titles for the data columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The first column that is printed out is the `index` of the DataFrame. It is a unique identifier of a row and was automatically generated for us (but we can change it later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be convienient to only look at an excerpt of a `DataFrame`. Use `DataFrame.head()` to display the first few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start station</th>\n",
       "      <th>Start time</th>\n",
       "      <th>End station</th>\n",
       "      <th>End time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>2016-10-01 06:00:08 +0200</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2016-10-01 06:09:47 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169</td>\n",
       "      <td>2016-10-01 06:00:41 +0200</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2016-10-01 06:11:07 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211</td>\n",
       "      <td>2016-10-01 06:01:02 +0200</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2016-10-01 06:15:52 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>2016-10-01 06:01:20 +0200</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2016-10-01 06:15:04 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>2016-10-01 06:02:16 +0200</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2016-10-01 06:04:29 +0200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start station                 Start time  End station  \\\n",
       "0            283  2016-10-01 06:00:08 +0200        238.0   \n",
       "1            169  2016-10-01 06:00:41 +0200        175.0   \n",
       "2            211  2016-10-01 06:01:02 +0200        162.0   \n",
       "3            200  2016-10-01 06:01:20 +0200        163.0   \n",
       "4            157  2016-10-01 06:02:16 +0200        163.0   \n",
       "\n",
       "                    End time  \n",
       "0  2016-10-01 06:09:47 +0200  \n",
       "1  2016-10-01 06:11:07 +0200  \n",
       "2  2016-10-01 06:15:52 +0200  \n",
       "3  2016-10-01 06:15:04 +0200  \n",
       "4  2016-10-01 06:04:29 +0200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns\n",
    "\n",
    "We can select a column by indexing by the column title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016-10-01 06:00:08 +0200\n",
       "1    2016-10-01 06:00:41 +0200\n",
       "2    2016-10-01 06:01:02 +0200\n",
       "3    2016-10-01 06:01:20 +0200\n",
       "4    2016-10-01 06:02:16 +0200\n",
       "Name: Start time, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_stats['Start time'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple columns are selected by indexing with a list of column titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start time</th>\n",
       "      <th>End time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-01 06:00:08 +0200</td>\n",
       "      <td>2016-10-01 06:09:47 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01 06:00:41 +0200</td>\n",
       "      <td>2016-10-01 06:11:07 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-01 06:01:02 +0200</td>\n",
       "      <td>2016-10-01 06:15:52 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-01 06:01:20 +0200</td>\n",
       "      <td>2016-10-01 06:15:04 +0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-01 06:02:16 +0200</td>\n",
       "      <td>2016-10-01 06:04:29 +0200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Start time                   End time\n",
       "0  2016-10-01 06:00:08 +0200  2016-10-01 06:09:47 +0200\n",
       "1  2016-10-01 06:00:41 +0200  2016-10-01 06:11:07 +0200\n",
       "2  2016-10-01 06:01:02 +0200  2016-10-01 06:15:52 +0200\n",
       "3  2016-10-01 06:01:20 +0200  2016-10-01 06:15:04 +0200\n",
       "4  2016-10-01 06:02:16 +0200  2016-10-01 06:04:29 +0200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_stats[['Start time', 'End time']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Oslo cycles opens at 6 in the morning. We can see the final rows with `tail()`. Pass in a number to tell Pandas how many rows you are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start time</th>\n",
       "      <th>End time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242755</th>\n",
       "      <td>2016-10-31 23:54:28 +0100</td>\n",
       "      <td>2016-11-01 00:01:59 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242756</th>\n",
       "      <td>2016-10-31 23:56:57 +0100</td>\n",
       "      <td>2016-11-01 00:02:16 +0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242757</th>\n",
       "      <td>2016-10-31 23:59:10 +0100</td>\n",
       "      <td>2016-11-01 00:04:55 +0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Start time                   End time\n",
       "242755  2016-10-31 23:54:28 +0100  2016-11-01 00:01:59 +0100\n",
       "242756  2016-10-31 23:56:57 +0100  2016-11-01 00:02:16 +0100\n",
       "242757  2016-10-31 23:59:10 +0100  2016-11-01 00:04:55 +0100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_stats[['Start time', 'End time']].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Oslo bysykkel closes at midnight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change type of columns\n",
    "Pandas tries to automatically detect the type of a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Start station      int64\n",
       "Start time        object\n",
       "End station      float64\n",
       "End time          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_stats.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this automatic detection failed for both `Start time` and `End time`: their `dtype` is `object` instead of a `date` type. \n",
    "\n",
    "In order to be able to sort or filter by date, we need to tell Pandas that these columns should be parsed as dates. We can do this directly when loading the data with the `parse_dates` parameter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_types = pd.read_csv('data/bysykkel/trips-2016.10.1-2016.10.31.csv', sep=',', parse_dates=['Start time', 'End time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_types.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Pandas has remove the timzone and shows the times now in GMT time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check the types with the `DataFrame.dtype` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bike_stats_types[\"Start time\"].dtype == np.dtype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: `End station` has been detected as `float` rather than `int`. This is because the `End station` column contains `Not a Number` (`NaN`) values , which cannot be represented as in the `int` type. Pandas chose instead the closest equivalent that supports `NaN`s, in the case a `float`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `plot` class method to plot our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_types['Start station'].head().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The x-axis is automatically labeld with the `index` of the row. We can also select a column to be used as label for the x-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `kind` parameter to control which kind of plot you want (read the docstring for `FataFrame.plot` to see a full list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_stats_types.plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing multiple columns results in multiple plot bars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_types[['Start station', 'End station']].head().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a column to be used as label for the x-axis (instead of the index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_types[['Start time', 'Start station', 'End station']].head().plot(x='Start time', y=['Start station', 'End station'], kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatter plot allows us to visualize from where to where people travelled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_types[['Start station', 'End station']].plot('Start station', 'End station', kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Now the x- and y-axis are labeld with the columns title. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By plotting the `Start station` as a histogram, we see how frequent each station "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_types['Start station'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Pandas seems to lump the station information, making this plot not too useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving/Converting data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A `DataFrame` can be saved again to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_stats.to_*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving as a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving as Latex table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats.head().to_latex(\"data.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat data.tex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to html:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats.head().to_html(\"data.html\")\n",
    "!google-chrome data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or convert to a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data from DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know this already: We can select a column by indexing with the column title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats['Start time'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A range of rows can be selected by indexing a slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A padding can be used to get every n'th row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats[5:50:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or combining them to the certain rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats['Start time'][5:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This also works:\n",
    "```python        \n",
    "bike_stats[5:15]['Start time']\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top ten bike stations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `DataFrame.value_counts` function to count how often each value occurs in a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats['Start station'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting these in a bar chart shows us the distribution of station usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats['Start station'].value_counts()[:100].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading json, setting index and plotting maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let us read in information about the each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python -m json.tool data/bysykkel/stations.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each station has a unique identifier (`id`) and some additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obvious thing would be to use `pd.read_json`:\n",
    "```python\n",
    "bike_stations = pd.read_json('data/bysykkel/stations')\n",
    "```\n",
    "**But**: this does not work. `read_json` expects the json to be in a specific format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we load the data with the `json` module to first read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json_stations = json.load(open('data/bysykkel/stations.json', 'r'))\n",
    "json_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the node `stations`, so let's extract this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_json = json_stations['stations']\n",
    "station_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `pandas.io.json_normalize` function to read in the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations = pd.io.json.json_normalize(station_json)\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the index\n",
    "\n",
    "Since each row in our station table is uniquely identified by the station id, it makes sense to use this column as the index for the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations = stations.set_index('id')\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The `id` data column has been removed and is now the index. This means that we cannot extract the id column anymore with:\n",
    "```python\n",
    "stations[\"id\"]  # Fails - does not exist anymore\n",
    "```\n",
    "Instead use:\n",
    "```python\n",
    "stations.index\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index will be used, e.g. for row labels when plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations[\"number_of_locks\"].plot(\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing columns\n",
    "\n",
    "Some of the columns are not so usefull so we would like to remove them.\n",
    "\n",
    "We can extract a subset of the DataFrame with:\n",
    "```python\n",
    "Dataframe.drop([Column Name or list], axis=1)\n",
    "```\n",
    "Lets reduce our stations to the usefull columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations = stations.drop([\"bounds\", \"subtitle\"], axis=1)\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract parts of our `DataFrame` with \n",
    "```python\n",
    "DataFrame.loc[startrow:endrow,startcolumn:endcolumn]\n",
    "```\n",
    "So for example if we are interested in the GPS positions for the stations with id 130-140 we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations.loc[160:170, \"center.latitude\":\"center.longitude\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can mathematical functions such as `min`, `max` or `mean` to get some information about a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"min number of locks:  {}\".format(stations[\"number_of_locks\"].min()))\n",
    "print(\"max number of locks:  {}\".format(stations[\"number_of_locks\"].max()))\n",
    "print(\"mean number of locks: {}\".format(stations[\"number_of_locks\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can `where` statments to find rows that satisfy certain conditions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "large_stations = stations[stations[\"number_of_locks\"] > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(large_stations), len(stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding columns\n",
    "New columns can be added by assigning data to a new column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations['random'] = np.random.random(len(stations))\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting maps\n",
    "\n",
    "It would be nice to plot the stations in a Google Maps map. We use the module `gmplot` for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gmplot\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(59.915620, 10.762248, zoom=12)\n",
    "gmap.draw(\"mymap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now open up the `mymap.html` with our favorite browser, or simply in the IPython notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the plot\n",
    "from IPython.display import IFrame\n",
    "#IFrame('mymap.html', width=700, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract the stations longtitude, latitude and location tile: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations[[\"center.latitude\", \"center.longitude\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = stations[\"center.latitude\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add it to our plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from insertapikey import insertapikey\n",
    "gmap.scatter(stations[\"center.latitude\"].values, stations[\"center.longitude\"].values, size=10, marker=True)\n",
    "gmap.draw(\"mymap_with_stations.html\")\n",
    "insertapikey(\"mymap_with_stations.html\") # API key needed for Google\n",
    "#IFrame('mymap_with_stations.html', width=700, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot](images/gm.png \"Bike stations in Google Maps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating and merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating Panda objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data so far only contained the statistics for October 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_types[\"Start time\"].min(), bike_stats_types[\"Start time\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also load the data for September 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_september = pd.read_csv('data/bysykkel/trips-2016.9.1-2016.9.30.csv', sep=',', parse_dates=['Start time', 'End time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To concatenate the two, we use the `concat` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_sep_oct = pd.concat((bike_stats_september, bike_stats_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: An altnerative implementation is \n",
    "```\n",
    "bike_stats_sep_oct = bike_stats_september.append(bike_stats_types)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check again that we indeed have the full range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_sep_oct[\"Start time\"].min(), bike_stats_sep_oct[\"Start time\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrames\n",
    "\n",
    "So far our bike statistics stores the bike stations as abstract integeres:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_stats_sep_oct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wouldn't it be nice to add more information about the station? We can do this by merging the information in the `stations` DataFrame into the `bike_stats_sep_oct` DataFrame. The syntax for merging two tables with the most important arguments is:\n",
    "\n",
    "```python\n",
    "pd.merge(left, right, how='inner', left_on=None, right_on=None, right_index=None, left_index=None)\n",
    "```         \n",
    "The arguments mean the following:\n",
    "* `left`: A DataFrame object\n",
    "* `right`: Another DataFrame object\n",
    "* `left_on`: Columns from the left DataFrame to use as keys. \n",
    "* `right_on`: Columns from the right DataFrame to use as keys.\n",
    "* `right_index`: Use index of the right DataFrame as key.\n",
    "* `left_index`: Use index of the right DataFrame as key.\n",
    "* `how`: One of 'left', 'right', 'outer', 'inner'. Defaults to inner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out. First, lets check the names of our columns again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bike_stats_sep_oct.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(stations.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to merge in the columns `bike_stats_sep_oct[\"Start station\"]` with the index for `stations`. We merge call is therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_bike_stats = pd.merge(bike_stats_sep_oct, stations, how='left', left_on=\"Start station\", right_index=True)\n",
    "merged_bike_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we still have all the data rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(merged_bike_stats))\n",
    "print(len(bike_stats_sep_oct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wohooo!\n",
    "\n",
    "Let us do the same for `End station`. To avoid overlapping column names, we use the `suffices` arguments, which automatically appends a suffix for duplicate column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_bike_stats2 = pd.merge(merged_bike_stats, stations, how='left', left_on=\"End station\", right_index=True, suffixes=(\"_start\", \"_end\"))\n",
    "merged_bike_stats2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the busiest stations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first find the busiest station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "busy_station = merged_bike_stats2['Start station'].value_counts()[:5]\n",
    "busy_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stations.loc[busy_station.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets filter out all statistics of this station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats = merged_bike_stats[merged_bike_stats[\"Start station\"] == busy_station.index[0]]\n",
    "ak_plass_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats = ak_plass_stats.set_index(\"Start time\")\n",
    "ak_plass_stats[:100].plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What is the usage of the citybikes for each weekday? \n",
    "(inspired by this [Pandas cookbook](https://github.com/jvns/pandas-cookbook/blob/master/cookbook/Chapter%204%20-%20Find%20out%20on%20which%20weekday%20people%20bike%20the%20most%20with%20groupby%20and%20aggregate.ipynb))\n",
    "It would be interesting to see on which weekdays people use the bikes the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a 'weekday' column to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats.index.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats.index.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the days of the week, where 0 is Monday and 6 is Sunday. \n",
    "\n",
    "Now that we know how to get the weekday, we can add it as a column in our dataframe like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats_cpy = ak_plass_stats.copy()\n",
    "ak_plass_stats['weekday'] = ak_plass_stats.index.weekday\n",
    "ak_plass_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add a counter to one - we will later add all the rows with common weekdays and the counter will tell us how many trips we added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats['counter'] = 1\n",
    "ak_plass_stats = ak_plass_stats[['weekday', 'counter']]\n",
    "ak_plass_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding up the cyclists by weekday\n",
    "\n",
    "Dataframes have a .groupby() method that is similar to SQL groupby, if you're familiar with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats.groupby?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this case, \n",
    "```python\n",
    "ak_plass_stats.groupby('weekday').aggregate(sum)\n",
    "```\n",
    "means \"Group the rows by weekday and then add up all the values with the same weekday\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekday_counts = ak_plass_stats.groupby('weekday').aggregate(sum)\n",
    "weekday_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's change the index to something more meaningful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekday_counts.index = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekday_counts.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is the usage across different hours of the day? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same strategy to find out how busy the city bikes are at certain hours of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats['hour'] = ak_plass_stats.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_plass_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hour_counts = ak_plass_stats[[\"hour\", \"counter\"]].groupby('hour').aggregate(sum)\n",
    "hour_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hour_counts.plot(kind=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
